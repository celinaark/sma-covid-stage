{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des Résultats des Simulations du Modèle SEIR Multi-Agent\n",
    "\n",
    "Ce notebook a pour objectif de lire les résultats de multiples réplications de simulations du modèle SEIR, de calculer les moyennes des états S, E, I, R à chaque pas de temps, et de visualiser ces dynamiques moyennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob # Pour trouver facilement les fichiers CSV\n",
    "\n",
    "# Style pour les graphiques (optionnel, mais améliore le visuel)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et Paramètres\n",
    "\n",
    "Définissez ici le chemin vers le dossier contenant les fichiers CSV des résultats et le préfixe des fichiers si nécessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers le dossier contenant les fichiers CSV\n",
    "# IMPORTANT : Modifiez cette variable pour qu'elle pointe vers le dossier où vos fichiers CSV sont sauvegardés\n",
    "DOSSIER_RESULTATS = './' # Exemple: './resultats_simulations/' ou le répertoire courant\n",
    "\n",
    "# Préfixe commun des fichiers de résultats (si applicable, sinon laisser vide ou adapter le glob)\n",
    "# Par exemple, si vos fichiers sont nommés \"toy_model_repl_1_seed0.csv\", \"toy_model_repl_2_seed1.csv\", etc.\n",
    "PREFIXE_FICHIER = 'toy_model_repl_'\n",
    "SUFFIXE_FICHIER = '.csv'\n",
    "\n",
    "# Nombre total de réplications attendu\n",
    "NOMBRE_REPLICATIONS = 100 # Doit correspondre au nombre de fichiers CSV générés\n",
    "\n",
    "# Nombre d'itérations par simulation\n",
    "NB_ITERATIONS_SIMU = 730 # Doit correspondre au nombre de lignes de données par CSV (hors en-tête)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Lecture et Chargement des Données de Toutes les Réplications\n",
    "\n",
    "Nous allons maintenant lire tous les fichiers CSV correspondant à nos réplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construire le motif de recherche pour les fichiers CSV\n",
    "# S'assure que le dossier se termine par un slash s'il est spécifié et non vide\n",
    "if DOSSIER_RESULTATS and not DOSSIER_RESULTATS.endswith('/'):\n",
    "    DOSSIER_RESULTATS += '/'\n",
    "\n",
    "motif_recherche = f\"{DOSSIER_RESULTATS}{PREFIXE_FICHIER}*{SUFFIXE_FICHIER}\"\n",
    "print(f\"Motif de recherche des fichiers : {motif_recherche}\")\n",
    "\n",
    "tous_les_fichiers_csv = glob.glob(motif_recherche)\n",
    "\n",
    "# Trier les fichiers pour s'assurer d'un ordre cohérent si nécessaire (optionnel)\n",
    "# tous_les_fichiers_csv.sort() \n",
    "\n",
    "if not tous_les_fichiers_csv:\n",
    "    print(f\"ERREUR : Aucun fichier CSV trouvé dans '{DOSSIER_RESULTATS}' avec le préfixe '{PREFIXE_FICHIER}'. Vérifiez le chemin et le préfixe.\")\n",
    "else:\n",
    "    print(f\"Nombre de fichiers CSV trouvés : {len(tous_les_fichiers_csv)}\")\n",
    "    if len(tous_les_fichiers_csv) != NOMBRE_REPLICATIONS:\n",
    "        print(f\"ATTENTION : {len(tous_les_fichiers_csv)} fichiers trouvés, mais {NOMBRE_REPLICATIONS} étaient attendues.\")\n",
    "\n",
    "# Liste pour stocker les DataFrames de chaque réplication\n",
    "liste_dataframes_replications = []\n",
    "\n",
    "for i, nom_fichier in enumerate(tous_les_fichiers_csv):\n",
    "    try:\n",
    "        df_repl = pd.read_csv(nom_fichier)\n",
    "        # Vérification basique de la structure\n",
    "        if 'iteration' in df_repl.columns and len(df_repl) == (NB_ITERATIONS_SIMU + 1): # +1 pour la ligne d'itération 0\n",
    "             # Ajouter une colonne pour identifier la réplication\n",
    "            df_repl['replication_id'] = i + 1 # ou extraire l'ID du nom de fichier si pertinent\n",
    "            liste_dataframes_replications.append(df_repl)\n",
    "        else:\n",
    "            print(f\"ATTENTION: Le fichier {nom_fichier} ne semble pas avoir le bon format (colonnes manquantes ou nombre d'itérations incorrect). Il sera ignoré.\")\n",
    "            print(f\"  Colonnes trouvées: {df_repl.columns.tolist()}, Lignes trouvées: {len(df_repl)}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la lecture du fichier {nom_fichier}: {e}\")\n",
    "\n",
    "if liste_dataframes_replications:\n",
    "    print(f\"\\n{len(liste_dataframes_replications)} DataFrames de réplication chargés avec succès.\")\n",
    "    # Afficher un aperçu du premier DataFrame chargé (optionnel)\n",
    "    # print(\"\\nAperçu du premier DataFrame chargé (premières lignes) :\")\n",
    "    # print(liste_dataframes_replications[0].head())\n",
    "else:\n",
    "    print(\"\\nERREUR : Aucun DataFrame n'a pu être chargé. Vérifiez les fichiers CSV et les messages d'erreur précédents.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Agrégation des Données\n",
    "\n",
    "Si les DataFrames ont été chargés, nous les combinons en un seul grand DataFrame, puis nous calculons les moyennes pour chaque état (S, E, I, R) à chaque pas de temps (itération) sur l'ensemble des réplications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if liste_dataframes_replications:\n",
    "    # Concaténer tous les DataFrames en un seul\n",
    "    df_complet = pd.concat(liste_dataframes_replications, ignore_index=True)\n",
    "    \n",
    "    print(\"\\nAperçu du DataFrame combiné (premières et dernières lignes) :\")\n",
    "    print(df_complet.head())\n",
    "    print(\"...\")\n",
    "    print(df_complet.tail())\n",
    "    \n",
    "    # Calculer les moyennes pour S, E, I, R pour chaque itération\n",
    "    # Le groupby sur 'iteration' va regrouper toutes les lignes ayant le même numéro d'itération (provenant des différentes réplications)\n",
    "    # Ensuite, .mean() calcule la moyenne pour chaque colonne numérique (S, E, I, R) pour ces groupes.\n",
    "    df_moyennes = df_complet.groupby('iteration')[['S', 'E', 'I', 'R']].mean()\n",
    "    \n",
    "    # Optionnel: calculer aussi l'écart-type ou d'autres statistiques\n",
    "    df_std = df_complet.groupby('iteration')[['S', 'E', 'I', 'R']].std()\n",
    "    df_min = df_complet.groupby('iteration')[['S', 'E', 'I', 'R']].min()\n",
    "    df_max = df_complet.groupby('iteration')[['S', 'E', 'I', 'R']].max()\n",
    "\n",
    "    print(\"\\nTableau des moyennes par itération (premières lignes) :\")\n",
    "    print(df_moyennes.head())\n",
    "else:\n",
    "    print(\"\\nPas de données à agréger car aucun DataFrame n'a été chargé.\")\n",
    "    df_moyennes = pd.DataFrame() # Créer un DataFrame vide pour éviter les erreurs suivantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualisation des Résultats Moyens\n",
    "\n",
    "Nous allons maintenant tracer les courbes moyennes de S, E, I, et R en fonction du temps (itérations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_moyennes.empty:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    plt.plot(df_moyennes.index, df_moyennes['S'], label='Susceptibles (S) - Moyenne')\n",
    "    plt.plot(df_moyennes.index, df_moyennes['E'], label='Exposés (E) - Moyenne')\n",
    "    plt.plot(df_moyennes.index, df_moyennes['I'], label='Infectieux (I) - Moyenne')\n",
    "    plt.plot(df_moyennes.index, df_moyennes['R'], label='Rétablis (R) - Moyenne')\n",
    "    \n",
    "    # Optionnel: Afficher les intervalles de confiance ou min/max\n",
    "    # plt.fill_between(df_moyennes.index, df_min['I'], df_max['I'], color='red', alpha=0.1, label='Min/Max Infectieux')\n",
    "\n",
    "    plt.title('Dynamique Moyenne du Modèle SEIR sur {} Réplications'.format(len(liste_dataframes_replications) if liste_dataframes_replications else 'N/A'))\n",
    "    plt.xlabel('Temps (jours/itérations)')\n",
    "    plt.ylabel(\"Nombre d'individus\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Impossible de générer le graphique car les données moyennes sont vides.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (Optionnel) Visualisation des Écarts-Types ou Intervalles de Confiance\n",
    "\n",
    "Si vous avez calculé les écarts-types, vous pouvez les visualiser ici pour montrer la variabilité entre les simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple pour tracer les moyennes avec une bande pour l'écart-type (si df_std a été calculé)\n",
    "if not df_moyennes.empty and 'df_std' in locals() and not df_std.empty :\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    for state in ['S', 'E', 'I', 'R']:\n",
    "        mean_values = df_moyennes[state]\n",
    "        std_values = df_std[state]\n",
    "        \n",
    "        plt.plot(df_moyennes.index, mean_values, label=f'{state} - Moyenne')\n",
    "        plt.fill_between(df_moyennes.index, mean_values - std_values, mean_values + std_values, alpha=0.2, label=f'{state} - Écart-type')\n",
    "\n",
    "    plt.title('Dynamique Moyenne du Modèle SEIR avec Écart-Type sur {} Réplications'.format(len(liste_dataframes_replications)))\n",
    "    plt.xlabel('Temps (jours/itérations)')\n",
    "    plt.ylabel(\"Nombre d'individus\")\n",
    "    # Pour éviter trop de labels si on trace S,E,I,R et leurs std séparément, on peut gérer la légende plus finement\n",
    "    # plt.legend() # Peut devenir chargé, ajuster au besoin\n",
    "    handles, labels = plt.gca().get_legend_handles_labels()\n",
    "    # Filtrer pour n'avoir que les labels de moyenne ou créer des labels personnalisés\n",
    "    # Par exemple, prendre un label sur deux si chaque plot + fill_between ajoute un label\n",
    "    unique_labels = {}\n",
    "    for i, label in enumerate(labels):\n",
    "        if label not in unique_labels:\n",
    "            unique_labels[label] = handles[i]\n",
    "    plt.legend(unique_labels.values(), unique_labels.keys())\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Graphique avec écart-type non généré (données manquantes).\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
